layer {
  name: "input"
  type: "Input"
  top: "input"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 18
      dim: 192
      dim: 192
    }
  }
}
layer {
  name: "convi"
  type: "Convolution"
  bottom: "input"
  top: "convi"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: true
    pad: 0
    pad: 2
    pad: 2
    kernel_size: 1
    kernel_size: 5
    kernel_size: 5
    stride: 1
    stride: 1
    stride: 1
    weight_filler {
      type: "msra"
      std: 1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elui"
  type: "ELU"
  bottom: "convi"
  top: "convi"
}
layer {
  name: "conv0_d0"
  type: "Convolution"
  bottom: "convi"
  top: "conv0_d0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 28
    bias_term: false
    pad: 0
    pad: 1
    pad: 1
    kernel_size: 1
    kernel_size: 3
    kernel_size: 3
    stride: 1
    stride: 1
    stride: 1
    weight_filler {
      type: "msra"
      std: 1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn0_d0"
  type: "BatchNorm"
  bottom: "conv0_d0"
  top: "conv0_d0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale0_d0"
  type: "Scale"
  bottom: "conv0_d0"
  top: "conv0_d0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu0_d0"
  type: "ELU"
  bottom: "conv0_d0"
  top: "output"
}
