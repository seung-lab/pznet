\section{Problem definition and motivation}

  Calculating Eq. (\ref{eq:forward}) requires 9 nested loops over the
  indices $b,f',n_x',n_y',n_z',f,k_x,k_y,k_z$, where the $n$ indices
  specify locations in an output image and the $k$ indices specify
  locations in a kernel.  In the innermost loop, one multiplication
  and one addition is performed.  Thus, the computation requires a
  total of $2BFF'N_x'N_y'N_z'K_zK_yK_z$ floating point operations
  (FLOPs).  We found that a naive C++ implementation utilized less
  than $1.1\%$ of a CPU core's theoretical maximum of $80$ GFLOPS.
  The code was compiled using all relevant optimization switches
  including the ones enabling AVX2 and FMA.

  Efficiency
  requires maximal utilization of the up to two FMA vector units per
  core.  Each FMA vector unit is capable of performing $2S$ floating
  point instructions per cycle via a fused multiply--add operation ($y
  = a\cdot x + b$).  Here $S$ is the width of the vector register (how
  many floating point numbers fit inside the register).  The peak
  performance of a single core is reached when, in each cycle, all
  available FMA units perform a fused multiply--add operation with the
  input stored in the register file.

  Another constraint is that the CPU must wait $l$ cycles for the
  output of the FMA unit, where $l$ is the latency of the unit.  To
  fully utilize the $n$ FMA units, a program must continuously issue
  FMA instructions such that no $nl$ consecutive instructions are
  dependent (a result of one instruction is an input for some other
  one).

  Finally, one should re--use data in the register file as much as
  possible, because loading new data from memory to a register incurs
  overhead.  And the data should be properly aligned in memory to
  speed up loading to the register.

  Since modern compilers are aware of the above constraints, our
  strategy is to write the computation in such a way that the
  compiler can optimize for efficient use of a single core.

%%%%%% removed since this is covered in the scheduling section
%  At compile-time, the computation is also divided into independent
%  sub--tasks, which are evenly distributed across the available
%  cores. A single fork--join execution, allows for minimal
%  synchronization, while each core will starts and ends its work at
%  roughly the same time.  As we will see, this enables efficient
%  utilization of all cores.
