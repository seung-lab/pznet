\section{Problem definition and motivation}

  Each element $I'(b,f',n_x',n_y',n_z')$ of the tensor computed via
  {\footnotesize
  \begin{equation}
  \sum_{f} \sum_{k_x} \sum_{k_y} \sum_{k_z}
  I(b,f,n_x+k_x,n_y+k_y,n_z+k_z) \cdot W(f',f,k_x,k_y,k_z)
  \label{eqn:forward}
  \end{equation}
  } Computing all the output images can be easily implemented as 9
  nested loops over $b,f',n_x',n_y',n_z',f,k_x,k_y,k_z$, with an
  arbitrary nesting order.  In the innermost loop, one multiplication
  and one addition is performed.  Thus, we need total of
  $2BFF'N_x'N_y'N_z'K_zK_yK_z$ floating point operations (FLOPs) to
  compute the result.  We implemented such approach in C++ and
  measured the speed of the implementation in GFLOPS (Giga FLOPS per
  second) by dividing the FLOPs required by the time taken to perform
  the computation.  While running on a CPU core capable of $80$
  GFLOPS, the average measured speed was $0.87$ GFLOPS -- less than
  $1.1\%$ utilization.  The code was compiled using all optimization
  switches including the ones enabling AVX2 and FMA that were
  available.

  This come as no surprise, as modern CPUs can achieve high
  performances only under very special circumstances.  Mainly, each
  core of modern CPUs has up to two FMA vector units each of which is
  capable of performing $2S$ floating point instructions per cycle via
  a fused multiply--add operation ($y = a\cdot x + b$).  Here, $S$ is
  the width of the vector register (how many floating point numbers
  fit inside the register).  The peak performance of a single core is
  then reached when, in each cycle, all available FMA units perform a
  fused multiply--add operation with the input stored in the register
  file.  Additionally, each CPU has a different latency of the FMA
  units.  This means that the result of the computation is not
  immediately available, but rather after $l$ cycles, where $l$ is the
  latency of the unit.  To fully utilize the $n$ FMA units, a program
  must continuously issue FMA instructions such that no $nc$
  consecutive instructions are dependent (a result of one instruction
  is an input for some other one).  Modern compilers are aware of
  these limitations, and will try to assemble the code in the most
  optimal way.

  Loading data from memory to a register introduces an additional
  overhead.  Thus, to achieve high performance, one must minimize such
  data transfers and re--use data in the register file as much as
  possible.  Furthermore, to speedup the loading of data from memory
  to the register requires the data to be properly aligned in memory.

  Our first motivation comes from the fact that there is a room of $90
  \times$ improvement of the serial algorithm over the naive approach.
  A bit about the solution for the serial algo.

  Efficiently utilizing CPUs with multiple cores introduce an
  additional constraint.  In order to fully utilize all available
  cores, they must perform independent computation and minimize
  synchronization.  A core shouldn't wait for a result computed by
  another core.

  Because of these constraints, the naive way of computing
  convolutions is very inefficient.  Designing an algorithm that
  follows all the constraints is challenging.  To design such
  algorithm, we are motivated by the following two principles.  First,
  we divide computation into small sub--tasks.  We provide a
  relatively simple implementation for each task so that the compiler
  can generate optimal machine code.  Secondly, the computation will
  be evenly distributed among the available cores, such that each core
  does an equal amount of work.  This minimal synchronization is
  necessary and each core can start and ends the computation at the
  same time.

  A bit about the motivation and solution of the parallel algo
