\section{Conclusion and closing remarks}

1) Good and consistent performances, portable, scalable

2) Easy to implement few hundred lines of generous c++ templated code

3) Just scratched the surface, additional optimizations such as
padding to avoid associativity conflicts, exhaustive search for optimal subdivisions, etc...

4) Not as satisfied with KNL performaces, expect improvement as compilers improve?

5) Provide open source implementation which should not be considered production ready

6) Possible to include the primitives into caffe or other frameworks,
by dynamic library compilation and loading.

7) Very useful for inference, as the size of the input matters and
CPUs have much more memory available (also beating ZNNi by a lot)

8) Applications using trained networks (our approach utilizes high
percentage of FLOPS even on SSE4 and AVX, not shown in the experiments
section).  This can be beneficial for consumer apps....
