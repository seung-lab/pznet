\section{Update phase}

  %% \begin{figure*}
  %%   \begin{minipage}[t][][b]{0.4\textwidth}
  %%     \begin{center}
  %%       \includegraphics[width=0.97\linewidth]{fig/static2}
  %%     \end{center}
  %%     \caption{Computing the values of $F'=3$ channels of 2D images of
  %%       size $4 \times 3$ using $T=2$ threads.  The three columns
  %%       represent three stages.  The dark blue/red represent the values
  %%       scheduled to be computed by $1^{st}/2^{nd}$ core.}
  %%     \label{fig:problem-subdivision}
  %%   \end{minipage}
  %%   \hspace{1ex}
  %%   \begin{minipage}[t][][b]{0.50\textwidth}
  %%     \resizebox{\textwidth}{!}{%
  %%       \centering
  %%       \includegraphics[width=0.87\linewidth]{fig/update2}
  %%     }
  %%     %\vspace{4.0ex}
  %%     \caption{Decomposing cross--correlation.}
  %%     \label{fig:conv-decomposition}
  %%   \end{minipage}
  %% \end{figure*}

  Similarly as in the fwd--bwd algorithm, our update phase algorithm
  consists of the following stack of primitives.

  In the update phase, each of the $F$ input images from the previous
  forward pass is cross--correlated with each of the $F'$ gradients
  with respect to the output obtained during the backward pass to
  produce $S^2$ gradients with respect to the kernel weights each of
  size $W_Z \times W_Y \times X$ -- the size of the kernel.  For
  simplicity, we will refer to the input images as simply ``images'',
  to the gradients with respect to the output as simply ``gradients'',
  and gradients with respect to the kernel weights as ``kernel
  gradients''.

  \begin{enumerate}
    \item {\bf Sub--kernel primitive} -- a primitive that computes a
      cross--correlation of each of $S$ images of size $R_Z \times R_Y
      \times (X + R_X - 1)$ with $S$ gradients of size $1 \times 1
      \times X$ to produce and accumulate the results of $S^2$ kernel
      gradients of size $R_Z \times R_X \times R_Y$.  As in the
      fwd--bwd case, this primitive is optimized for efficiently
      reusing the register file as well as $L1$ cache.
    \item {\bf Full kernel primitive} -- a primitive that computes
      cross--correlation of an arbitrary sized $S$ images with
      arbitrary sized $S$ gradients to produce $S^2$ kernel gradients.
    \item {\bf Sub--layer primitive} -- a primitive that computes
      $\alpha \times \beta \times S^2$ kernel gradients by
      cross--correlating each of $\alpha S$ images with $\beta S$
      gradients.
    \item {\bf Full layer primitive} -- parallelized primitive that
      divides the computation into a set of previous primitives and
      statically schedules execution.  As described below, this
      primitive might need to contain an extra parallelized reduction
      step, which is also statically scheduled.
  \end{enumerate}


  \begin{algorithm}
    {\footnotesize
      \begin{codebox}
        \Procname{$\proc{Update-Subtask} \langle R_Z, R_Y, R_X, X, R_S \rangle(a,b,r)$}
        \li \kw{simd register} $oreg[R_Z][R_Y][R_X][R_S]$
        \li \kw{simd register} $wreg$
        \li \For $s_0 \gets 0 \To S/R_S - 1$
        \li \Do $oreg[:][:][:][:][:] \gets \proc{LOAD}(r[:][:][:][:][:])$
        \li \For $i \gets 0 \To X-1$ \Comment Partially unrolled
        \li   \Do $wreg \gets \proc{LOAD}(b[1][1][i][:])$
        \li   \For $z \gets 0 \To R_Z-1$ \Comment Fully unrolled
        \li   \Do \For $y \gets 0 \To R_Y-1$  \Comment Fully unrolled
        \li   \Do \For $x \gets 0 \To R_X-1$  \Comment Fully unrolled
        \li   \Do \For $s_1 \gets 0 \To R_S-1$   \Comment Fully unrolled
        \li   \Do $oreg[z][y][x][s_0 \cdot R_S + s] \gets \proc{FMADD}($
        \li   \Do $wreg,$
        \li       $\proc{EXLOAD}(a[z][y][x+i][s_0 \cdot R_S + s]),$
        \li       $oreg[z][y][x][])$
        \End
        \End \li \kw{end for} $s$
        \End \li \kw{end for} $x$
        \End \li \kw{end for} $y$
        \End \li \kw{end for} $z$
        \End \li \kw{end for} $i$
        \li $r[:][:][:][:][:] \gets \proc{STORE}(oreg[:][:][:][:][:])$
        \End \li \kw{end for} $s_0$
      \end{codebox}
    \caption{Serial update subtask.}
    \label{alg:serial-update-subtask}
    }
  \end{algorithm}

  {\bf Sub--kernel primitive} \quad The lowest level primitive is
  shown in Algorithm~\ref{alg:serial-update-subtask}.  Each of the $S$
  images of size $R_Z \times R_Y \times (R_X + X - 1)$ stored in $a$
  are convolved with $S$ images of size $1 \times 1 \times X$ stored
  in $b$.  $R_S$ input images are considered at the time

  The result is then accumulated into $r$.  As in the
  fwd--bwd case we only allow $R_Z, R_Y, R_X$ and $R_S$ of certain
  size such that the $oreg$ can fit inside the register file.  The 4
  innermost loop are designed to maximize $L1$ cache hits, which can
  be approximated to $\frac{1}{R_Z \times R_Y \times R_X \times R_S}
  \approx \frac{1}{S}$.  This is higher than in the fwd--bwd case,
  however, the loop over $i$ ensures predictable memory access
  pattern, allowing for hardware pre--fetching.  Additional $L1$ reuse
  is ensured by the next primitive.

  {\bf Full kernel primitive} \quad Or next primitive computes $S^2$
  cross--correlations of $S$ arbitrary sized images with $S$
  gradients, to produce $S^2$ kernel gradients.  A cross--correlation
  can be decomposed into sum of more cross--correlations by dividing
  the correlation kernel into sub--images.  One such decomposition is
  shown on Fig.~\ref{conv-decomposition}.  In the first the $S$
  gradients of size $G_Z \times G_Y \times G_X$ are decomposed into
  $G_Z \times G_Y$ sub--gradients.  The result is then obtained as the
  sum of cross--correlation of $S$

   \begin{figure}
     \centering
     \includegraphics[width=0.99\linewidth]{fig/update2}
     \caption{An example of the {\bf full kernel primitive} and {\bf
         full gradient primitive} for the special case of $S=1$,...}
     \label{fig:conv-decomposition}
   \end{figure}

   {\bf Full kernel primitive} computes $S^2$ kernel gradients by
   cross--correlating each of $S$ images with $S$ gradients.  The
   computation is performed in two steps.  First, the gradients are
   split into sub--gradients of size $1 \times 1 \times X$.  The
   result is then obtained as the sum of cross--correlations of each
   of the sub--gradients with an appropriate sub--image, as depicted
   on Fig~\ref{conv-decomposition} (middle column).
